{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detection of HTTP injection attack using deep learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chibueze-20/Automatic-Detection-of-HTTP-injection-Attacks-using-CNN-and-DNN/blob/main/Detection_of_HTTP_injection_attack_using_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj8vCEBGzTSx"
      },
      "source": [
        "#Detecting HTTP injection attacks using DNN model and CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MunbaAq6y4HA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e047cb90-75ee-4358-b9b3-1547336a3628"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W829AEWkrjj3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras.losses as lossx\n",
        "from keras.layers import (Activation, Conv1D, Dense, Dropout, Embedding,\n",
        "                          Flatten, Input, MaxPooling1D)\n",
        "from keras.models import Model, Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9MLdd1s1MMU"
      },
      "source": [
        "##Define the helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCMyRhOHzFoM"
      },
      "source": [
        "###Extract dataset into pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHnsGUPfzCTb"
      },
      "source": [
        "def ExtractDataframe(csvdataset_path):\n",
        "    return pd.read_csv(csvdataset_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAdB0UYIzhdT"
      },
      "source": [
        "###Build the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJw80QtMzr4T"
      },
      "source": [
        "def BuildTokenizer(vocabulary,sequence):\n",
        "    char_dictionary={}\n",
        "    for index, char in enumerate(vocabulary):\n",
        "        char_dictionary[char] = index + 1\n",
        "    tokenizer = Tokenizer(num_words=None,char_level=True,oov_token='UNK',lower=False)\n",
        "    tokenizer.fit_on_texts(sequence)\n",
        "    tokenizer.word_index=char_dictionary\n",
        "    tokenizer.word_index[tokenizer.oov_token]= len(char_dictionary.values())+1\n",
        "    return tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKpUvXkOzvv1"
      },
      "source": [
        "###Get the maximum length of a http query or body"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZuyd9bzz9HN"
      },
      "source": [
        "def MaxRequestLength(requests):\n",
        "    max_length = 0\n",
        "    for request in requests:\n",
        "        if max_length<len(request):\n",
        "            max_length = len(request)\n",
        "    return max_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVICCB8u0AtD"
      },
      "source": [
        "###Preprocessing and dataset splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQesCykS0L_g"
      },
      "source": [
        "def PreprocessAndSplit(dataframe,vocabulary,test_split=0):\n",
        "    requests = dataframe['Parameters'].values\n",
        "    labels = dataframe['Label'].values\n",
        "    tokenizer=BuildTokenizer(vocabulary,requests)\n",
        "    character_indexes = tokenizer.texts_to_sequences(requests)\n",
        "    max_length = 840\n",
        "    data = pad_sequences(character_indexes,maxlen=max_length,padding='post')\n",
        "    targets = to_categorical(labels,num_classes=2)\n",
        "    if test_split==0:\n",
        "        return [tokenizer,max_length,len(tokenizer.word_index),data,targets]\n",
        "    else:\n",
        "        X_train,X_test,Y_train,Y_test = train_test_split(data,targets,test_size=test_split)\n",
        "        return [tokenizer,max_length,len(tokenizer.word_index),X_train,X_test,Y_train,Y_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQHhcjCE0P_1"
      },
      "source": [
        "###Build the CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW7U5fDY0Uco"
      },
      "source": [
        "def BuildCNN(embeddingSize,inputSize,conv_layers,fully_connected_layers,num_classes,dropout_p,optimizer,loss):\n",
        "    #model definition\n",
        "    #embedding layer definition\n",
        "    Embedding_layer = Embedding(embeddingSize+1,embeddingSize,input_length=inputSize)\n",
        "    #input layer\n",
        "    inputs = Input(shape=(inputSize,), name='input', dtype='int64')\n",
        "    #embedding layer\n",
        "    model = Embedding_layer(inputs)\n",
        "    #Conv layers\n",
        "    for filter_num, filter_size, pooling_size in conv_layers:\n",
        "        model = Conv1D(filter_num,filter_size)(model)\n",
        "        model = Activation('relu')(model)\n",
        "        if pooling_size !=-1:\n",
        "            model=MaxPooling1D(pool_size=pooling_size)(model)\n",
        "    #flatten layer\n",
        "    model = Flatten()(model)\n",
        "    #Fullly connected layers\n",
        "    for dense_size in fully_connected_layers:\n",
        "        model = Dense(dense_size,activation='relu')(model)\n",
        "        model = Dropout(dropout_p)(model)\n",
        "    #output layer\n",
        "    predictions = Dense(num_classes,activation='softmax')(model)\n",
        "    #model\n",
        "    CNNmodel = Model(inputs=inputs, outputs=predictions)\n",
        "    CNNmodel.compile(optimizer=optimizer,loss=loss,metrics=['accuracy'])\n",
        "    return CNNmodel\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecRiCO3U0VQ5"
      },
      "source": [
        "###Build the DNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeN_afDP0gKe"
      },
      "source": [
        "def BuildDNN(embeddingSize,inputSize,fully_connected_layers,num_classes,optimizer,loss):\n",
        "    #model definition\n",
        "    DNNmodel = Sequential()\n",
        "    #embedding layer definition\n",
        "    DNNmodel.add(Embedding(embeddingSize+1,embeddingSize,input_length=inputSize))\n",
        "    #flatten layer\n",
        "    DNNmodel.add(Flatten())\n",
        "    for nodes in fully_connected_layers:\n",
        "        DNNmodel.add(Dense(nodes,activation='relu'))\n",
        "        DNNmodel.add(Dropout(0.5))\n",
        "    #output layer\n",
        "    DNNmodel.add(Dense(num_classes,activation='softmax'))\n",
        "    #model\n",
        "    DNNmodel.compile(optimizer=optimizer,loss=loss,metrics=['accuracy'])\n",
        "    return DNNmodel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfzXkUz50v1Q"
      },
      "source": [
        "##Get dataset, preproces and build the DNN and CNN models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwh8FfPN5Ngo"
      },
      "source": [
        "###extract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nmLkqRz0_Ru"
      },
      "source": [
        "train_df = ExtractDataframe('/content/drive/My Drive/Dataset/dataset.csv')\n",
        "train_df = train_df.loc[:,['Parameters','Label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-7I36JG5RK7"
      },
      "source": [
        "###Preprocess and split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSEpRTSX5Vy8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "b44adc29-3b59-4c98-8568-ddd7b52142d4"
      },
      "source": [
        "data = PreprocessAndSplit(train_df,\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{} \",0.3)\n",
        "print(\"Max query lenght:\",data[1])\n",
        "print(\"Vocabulary Size:\",data[2])\n",
        "print(data[3],data[5],data[4],data[6],sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max query lenght: 840\n",
            "Vocabulary Size: 96\n",
            "[[12 15  1 ...  0  0  0]\n",
            " [19 60 19 ...  0  0  0]\n",
            " [ 7 54  7 ...  0  0  0]\n",
            " ...\n",
            " [ 4 20 14 ...  0  0  0]\n",
            " [ 1  5  8 ...  0  0  0]\n",
            " [19 15 20 ...  0  0  0]]\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n",
            "[[16  3 13 ...  0  0  0]\n",
            " [ 5 19  1 ...  0  0  0]\n",
            " [ 5 15 21 ...  0  0  0]\n",
            " ...\n",
            " [ 1  9 14 ...  0  0  0]\n",
            " [ 5  5  8 ...  0  0  0]\n",
            " [ 9 20 20 ...  0  0  0]]\n",
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtqwgqkP8Faq"
      },
      "source": [
        "###Create CNN Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlPZ6Vcr8LwB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3e30c5c-5867-4d5a-b999-b60150f54931"
      },
      "source": [
        "CnnModel = BuildCNN(data[2],data[1],[[256, 7, 3],[256, 7, 3],[256, 3, -1],[256, 3, -1],[256, 3, -1], \n",
        "               [256, 3, 3]],[1024,1024],2,0.5,'adam','categorical_crossentropy')\n",
        "CnnModel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 840)               0         \n",
            "_________________________________________________________________\n",
            "embedding_11 (Embedding)     (None, 840, 96)           9312      \n",
            "_________________________________________________________________\n",
            "conv1d_25 (Conv1D)           (None, 834, 256)          172288    \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 834, 256)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_13 (MaxPooling (None, 278, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_26 (Conv1D)           (None, 272, 256)          459008    \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 272, 256)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_14 (MaxPooling (None, 90, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_27 (Conv1D)           (None, 88, 256)           196864    \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 88, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_28 (Conv1D)           (None, 86, 256)           196864    \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 86, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_29 (Conv1D)           (None, 84, 256)           196864    \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 84, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_30 (Conv1D)           (None, 82, 256)           196864    \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 82, 256)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_15 (MaxPooling (None, 27, 256)           0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 6912)              0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1024)              7078912   \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 9,558,626\n",
            "Trainable params: 9,558,626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tThtzAd393na"
      },
      "source": [
        "###Build DNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-WuFbip97ck",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "cd48a09a-d20d-4d24-d940-39e7caec7894"
      },
      "source": [
        "DNNmodel = BuildDNN(data[2],data[1],[1024,1024],2,'sgd','categorical_crossentropy')\n",
        "DNNmodel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, 840, 96)           9312      \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 80640)             0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 1024)              82576384  \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 83,637,346\n",
            "Trainable params: 83,637,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRT5-JOw-5To"
      },
      "source": [
        "##Train DNN and CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS2dLVfz_GVy"
      },
      "source": [
        "###Train CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Lr4EFS--BV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "9c094456-b12a-4923-a8a9-c99650fd0d0e"
      },
      "source": [
        "CnnModel.fit(data[3],data[5],batch_size=128,epochs=5,validation_data=(data[4],data[6]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30180 samples, validate on 12935 samples\n",
            "Epoch 1/5\n",
            "30180/30180 [==============================] - 45s 1ms/step - loss: 0.3712 - acc: 0.8443 - val_loss: 0.2374 - val_acc: 0.9331\n",
            "Epoch 2/5\n",
            "30180/30180 [==============================] - 44s 1ms/step - loss: 0.1995 - acc: 0.9447 - val_loss: 0.1986 - val_acc: 0.9443\n",
            "Epoch 3/5\n",
            "30180/30180 [==============================] - 44s 1ms/step - loss: 0.1879 - acc: 0.9487 - val_loss: 0.2024 - val_acc: 0.9416\n",
            "Epoch 4/5\n",
            "30180/30180 [==============================] - 44s 1ms/step - loss: 0.1866 - acc: 0.9491 - val_loss: 0.1995 - val_acc: 0.9429\n",
            "Epoch 5/5\n",
            "30180/30180 [==============================] - 44s 1ms/step - loss: 0.1837 - acc: 0.9495 - val_loss: 0.1947 - val_acc: 0.9451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5ca9ca8908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEnb53RlGRAy"
      },
      "source": [
        "###Train DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLfgeM3hGUoX"
      },
      "source": [
        "DNNmodel.fit(data[3],data[5],batch_size=128,epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "226rElr8EUn6"
      },
      "source": [
        "CnnModel.evaluate(data[4],data[6])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}